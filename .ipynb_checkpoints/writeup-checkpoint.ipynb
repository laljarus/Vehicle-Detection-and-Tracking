{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writeup Template\n",
    "----\n",
    "\n",
    "**Vehicle Detection Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Training a SVM classifier to distinguish an image from vehicle and non vehicle objects. The following features in the image used to train the classifier\n",
    "    * Spatial binned colored features\n",
    "    * Histogram of colors\n",
    "    * Histogram of colored gradients\n",
    "\n",
    "* Implementation of sliding window technique accross the image to detec vehicles in the image\n",
    "* Implmentation of the algorithm on a video stream and application\n",
    "* Application of heatmap and labels to eliminate false positives and detecting bounding boxes for identified vehicles\n",
    "\n",
    "[//]: # (Image References)\n",
    "[image1]: (./examples/car_not_car.png)\n",
    "[image2]: ./examples/HOG_example.jpg\n",
    "[image3]: ./examples/sliding_windows.jpg\n",
    "[image4]: ./examples/sliding_window.jpg\n",
    "[image5]: ./examples/bboxes_and_heat.png\n",
    "[image6]: ./examples/labels_map.png\n",
    "[image7]: ./examples/output_bboxes.png\n",
    "[video1]: ./project_video.mp4\n",
    "\n",
    "## [Rubric](https://review.udacity.com/#!/rubrics/513/view) Points\n",
    "### Here the rubric points considered and described how  each point is addressed in the implementation.  \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the SVM Classifier\n",
    "\n",
    "A Support Vector Machine(SVM) is used in this project to detect the vehicles in an image. The SVM is trained as a binary classifier which classifies a given image into vehicle and non vehicle image. The SVM is trained using a labeled data provided by Udacity based on  GTI vehicle image database and KITTI vision benchmark suite. The dataset contains about 8800 images in each of the vheicle and non-vehicle categories. Each image in the traning dataset is of size 64 X 64 pixels, which is an approprioate size of a widow used in the image. For each input image several windows are slide accross the image and each window is passed to the SVM which classifies if the window is a image of a vehicle or not. The SVM is trained by extracting the following features from the input image\n",
    "\n",
    "    - Spatial binned colored features\n",
    "    - Histogram of colors\n",
    "    - Histogram of colored gradients\n",
    "    \n",
    "### Histogram of Colored Gradients\n",
    "\n",
    "Histogram of colored gradients(HOG) is the most important feature by the SVM to distinguish vehicle and non vehicle image.HOG of an image identifies the edges of the image and so the shape of the objects is detectable. The following image shows the HOG of a vehicle and HOG of a non vehicle images. \n",
    "\n",
    "![alt text](./examples/Hog_car_notcar.png)\n",
    "\n",
    "From the above image the differences between vehicle and non vehicle images are clearly visible. The outer shape of the vehicle is easily visible and also the objects in the vehicle such as taillights, tires are also visible. These details are used by the SVM to classify the images. The following parameters are used in the during the extraction of hog features during training and implementaiton. \n",
    "\n",
    "| Parameter|Value|\n",
    "|:-:|:-:|\n",
    "|Orientation|9|\n",
    "|Pixels per cell| 8|\n",
    "|Cells per Block|2|\n",
    "|HOG Channels|Grey|\n",
    "\n",
    "Choosing parameters for HOG is trade off between the speed and accuracy. For example the orientation, which parameter defines the bins used in calculating histogram of gradients, a high value of orientation improves the accuracy of the classifier but reduces the speed. The parameters above are chosen based on several trials. The parameter pixel per cell and cells per block decides the number of features. Having higher feature length increases the accuracy of the classifier but decreases the speed. The hog channel parameter grey means that the image is converted to grayscale before hog was calculated.\n",
    "\n",
    "### Histogram of Color Spaces\n",
    "\n",
    "The histogram of color is also a useful feature used for training the classifier since most vehicles have same colour throughout its body. If the color space is switched from RGB to other color spaces such as LUV or YcrCb the histogram of color channels is even more useful to distinguish vehicle and non vehicle images. In this project YCrCb color space is used. The following image shows the difference between vehicle and non vehicle images.\n",
    "\n",
    "![alt text](./examples/ColorHistogramFeatures.png)\n",
    "\n",
    "### Spatial Features\n",
    "\n",
    "Spatial features are extracted by just reducing the size of the image and arranging all the pixel values into a feature vector. The spatial feature has different for vehicle images and non vehicle images which is shown in the figure below.\n",
    "\n",
    "![alt text](./examples/SpatialFeatures.png)\n",
    "\n",
    "\n",
    "with the chosen set of parameters for extracting the features during the training of SVM, it acheives an accuracy of 99.32% for a feature vector of length 2628 for 64 X 64 window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Sliding Window and HOG Subsampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vehicle detection pipeline involves detecting vehicles in predefined regions called windows thorughtout the image. The features of the image are extracted from the image and classifed by the SVM.To define windows there are two methods sliding window method and hog subsampling method. In the sliding window method the windows of predefined sizes are swept thoughout the image and the image in the window is classified. This method is straight forward but computaion intesive as it involves calculating the HOG values of image for each window. The subsampling method is more efficient computationally since it involves calculating the HOG values once for overall image and the features are extracted from the precalulated HOG values with defined window sizes. In this project HOG subsampling method is used. The following pictures show the windows used in the image.\n",
    "\n",
    "![alt text](.\\examples\\SubSamplingWindows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Subsampling method the window sizes cannot be defined accurately since the whole image is scaled by a factor and keeping the window size constant, which is equal to the size of image used for training the classifier. The scaling factor determins the window sizes smallar the scaling factors smaller the window sizes. In this project three scaling factors are used in the following y axis ranges as shown in the table below\n",
    "\n",
    "|Scaling Factor|Y Start(pixels)|Y Stop(pixels)|\n",
    "|:-:|:-:|:-:|\n",
    "|1.2|400|528|\n",
    "|1.4|400|656|\n",
    "|2.2|464|720|\n",
    "\n",
    "In the subsampling method there is parameter called pixels per step which determines the overlap between the windows. The pixel per step is kept at 2 which corresponds to a overlap of 0.75 if pixels per cells value is equal to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
